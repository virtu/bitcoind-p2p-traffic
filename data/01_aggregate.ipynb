{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data\n",
    "\n",
    "By default, tracepoint and systemd IP accounting data is sampled every 5s by\n",
    "[nix-bitcoin-monitor](https://github.com/virtu/nix-bitcoin-monitor). This means\n",
    "there's a lot of data points, working with which can cause long runtimes. For\n",
    "traffic analysis, hourly or daily granularity is sufficient, so this notebook\n",
    "aggregates data in this fashion to make analysis more responsive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "opts = dict(compression=\"bz2\", index_col=0, parse_dates=True)\n",
    "df_tp = pd.read_csv(\"tracepoints_preprocessed.csv.bz2\", **opts)\n",
    "df_sys = pd.read_csv(\"systemd_preprocessed.csv.bz2\", **opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "TCP/IP traffic is estimated using the following assumptions:\n",
    "- MTU size is 1500 bytes (common default)\n",
    "- Bitcoin protocol overhead is 24 bytes (4-byte magic, 12-byte command, 4-byte\n",
    "  each for payload length and checksum)\n",
    "- TCP header size of 32 (default)\n",
    "- IPv4 and v6 header sizes of 20 and 40 bytes (default)\n",
    "\n",
    "The estimate uses the following approach. First, the application-level message\n",
    "size is computed by adding the Bitcoin P2P message overhead to the message size.\n",
    "Next, the number of TCP segments is computed by dividing the application-level\n",
    "size obtained during the previous step by the maximum segment size (which\n",
    "corresponds to the MTU minus TCP and IP headers) to compute the number of TCP\n",
    "segments. Then, the total TCP/IP overhead is computed (number of segments times\n",
    "TCP and IP header overhead). Finally, TCP/IP traffic is estimated by combining\n",
    "the application-level message size with the total TCP/IP overhead.\n",
    "\n",
    "Next, empirical TCP/IP measurements obtained via systemd accounting are combined\n",
    "with the estimate so the latter can be validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCP/IP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "def estimate_network_traffic(row):\n",
    "    MAX_MTU_SIZE = 1500\n",
    "    BITCOIN_PROTOCOL_OVERHEAD = 24\n",
    "    TCP_HEADER_SIZE = 32\n",
    "    IP_HEADER_SIZE = 40 if row[\"ipv6\"] else 20\n",
    "    MSS = MAX_MTU_SIZE - IP_HEADER_SIZE - TCP_HEADER_SIZE\n",
    "    bitcoin_message_size = row[\"size\"] + BITCOIN_PROTOCOL_OVERHEAD\n",
    "    num_segments = math.ceil(bitcoin_message_size / MSS)\n",
    "    tcpip_overhead = num_segments * (IP_HEADER_SIZE + TCP_HEADER_SIZE)\n",
    "    return bitcoin_message_size + tcpip_overhead\n",
    "\n",
    "\n",
    "df_tp[\"net_size\"] = df_tp.parallel_apply(estimate_network_traffic, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and aggregate data\n",
    "\n",
    "First, the dataframe contaiing empirical data from systemd's IP accounting is\n",
    "pivoted so it can be aggregated.\n",
    "\n",
    "Next, the pivoted df and the tracepoint df are aggregated to produce hourly and\n",
    "daily data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sys_t = (\n",
    "    df_sys.rename(columns={\"IPIngressBytes\": \"in\", \"IPEgressBytes\": \"out\"})[\n",
    "        [\"in\", \"out\"]\n",
    "    ]\n",
    "    .stack()\n",
    "    .rename(\"net_size\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_1\": \"flow\"})\n",
    "    .set_index(\"timestamp\")\n",
    ")\n",
    "\n",
    "\n",
    "def agg_sum(df, cols, freq, data=\"net_size\"):\n",
    "    \"\"\"Aggregate 'data' col based on datetime index with frequency 'freq', using\n",
    "    summation using 'cols' as differentiator.\"\"\"\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp[\"freq\"] = df_tmp.index.floor(freq)\n",
    "    df_result = (\n",
    "        df_tmp.groupby([\"freq\"] + cols)[\"net_size\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .set_index(\"freq\")\n",
    "    )\n",
    "    return df_result\n",
    "\n",
    "\n",
    "dfs = {\n",
    "    \"est_hourly\": agg_sum(df_tp, [\"flow\", \"msg_type\"], \"1h\"),\n",
    "    \"est_daily\": agg_sum(df_tp, [\"flow\", \"msg_type\"], \"1d\"),\n",
    "    \"emp_hourly\": agg_sum(df_sys_t, [\"flow\"], \"1h\"),\n",
    "    \"emp_daily\": agg_sum(df_sys_t, [\"flow\"], \"1d\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    df.to_csv(f\"data_{name}.csv.bz2\", compression=\"bz2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
