{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Aggregate data\n",
                "\n",
                "By default, tracepoint and systemd IP accounting data is sampled every 5s by\n",
                "[nix-bitcoin-monitor](https://github.com/virtu/nix-bitcoin-monitor). This means\n",
                "there's a lot of data points, working with which can cause long runtimes. For\n",
                "traffic analysis, hourly or daily granularity is sufficient, so this notebook\n",
                "aggregates data in this fashion to make analysis more responsive."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extract"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "File \u001b[0;32mlib.pyx:2391\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: Invalid object type",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:711\u001b[0m, in \u001b[0;36mParserBase._infer_types\u001b[0;34m(self, values, na_values, no_dtype_specified, try_num_bool)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     result, result_mask \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_numeric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_masked_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_default_dtype_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# e.g. encountering datetime string gets ValueError\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m#  TypeError can be raised in floatify\u001b[39;00m\n",
                        "File \u001b[0;32mlib.pyx:2433\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: Invalid object type at position 0",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m opts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbz2\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m df_tp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtracepoints_preprocessed.csv.bz2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_sys \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystemd_preprocessed.csv.bz2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:333\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    330\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[1;32m    332\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_date_conversions(names, data)\n\u001b[0;32m--> 333\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:372\u001b[0m, in \u001b[0;36mParserBase._make_index\u001b[0;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[1;32m    371\u001b[0m     simple_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_simple_index(alldata, columns)\n\u001b[0;32m--> 372\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_complex_date_col:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_processed:\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:504\u001b[0m, in \u001b[0;36mParserBase._agg_index\u001b[0;34m(self, index, try_parse_dates)\u001b[0m\n\u001b[1;32m    498\u001b[0m             index_converter \u001b[38;5;241m=\u001b[39m converters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names[i]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     try_num_bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    501\u001b[0m         cast_type \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(cast_type) \u001b[38;5;129;01mor\u001b[39;00m index_converter\n\u001b[1;32m    502\u001b[0m     )\n\u001b[0;32m--> 504\u001b[0m     arr, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_types\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_na_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol_na_fvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtry_num_bool\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[1;32m    509\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names\n",
                        "File \u001b[0;32m/nix/store/b85nj85lqi8sh73akvx7dd6c0bj99fcs-python3-3.11.9-env/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:720\u001b[0m, in \u001b[0;36mParserBase._infer_types\u001b[0;34m(self, values, na_values, no_dtype_specified, try_num_bool)\u001b[0m\n\u001b[1;32m    711\u001b[0m     result, result_mask \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_numeric(\n\u001b[1;32m    712\u001b[0m         values,\n\u001b[1;32m    713\u001b[0m         na_values,\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         convert_to_masked_nullable\u001b[38;5;241m=\u001b[39mnon_default_dtype_backend,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# e.g. encountering datetime string gets ValueError\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m#  TypeError can be raised in floatify\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m     na_count \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "opts = dict(compression=\"bz2\", index_col=0, parse_dates=True)\n",
                "df_tp = pd.read_csv(\"tracepoints_preprocessed.csv.bz2\", **opts)\n",
                "df_sys = pd.read_csv(\"systemd_preprocessed.csv.bz2\", **opts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Transform\n",
                "\n",
                "TCP/IP traffic is estimated using the following assumptions:\n",
                "- MTU size is 1500 bytes (common default)\n",
                "- Bitcoin protocol overhead is 24 bytes (4-byte magic, 12-byte command, 4-byte\n",
                "  each for payload length and checksum)\n",
                "- TCP header size of 32 bytes, comprising 20-byte minimum TCP header size plus 10-byte timestamps option (used by default by the Linux kernel to make real-time round-trip measurements) and two padding bytes to align options to 32-bit boundaries\n",
                "- IPv4 and v6 header sizes of 20 and 40 bytes (default)\n",
                "\n",
                "The estimate uses the following approach. First, the application-level message\n",
                "size is computed by adding the Bitcoin P2P message overhead to the message size.\n",
                "Next, the number of TCP segments is computed by dividing the application-level\n",
                "size obtained during the previous step by the maximum segment size (which\n",
                "corresponds to the MTU minus TCP and IP headers) to compute the number of TCP\n",
                "segments. Then, the total TCP/IP overhead is computed (number of segments times\n",
                "TCP and IP header overhead). Moreover, the overhead of ACKs is estimated to be\n",
                "half of the number of segments times the sum of IP and TCP header sizes, since\n",
                "generally ACKs are sent for every two packets.  Finally, TCP/IP traffic is\n",
                "estimated by combining the application-level message size with the total TCP/IP\n",
                "and ACK overhead.\n",
                "\n",
                "Next, empirical TCP/IP measurements obtained via systemd accounting are combined\n",
                "with the estimate so the latter can be validated."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TCP/IP estimate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO: Pandarallel will run on 8 workers.\n",
                        "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'df_tp' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     ack_overhead \u001b[38;5;241m=\u001b[39m (num_segments \u001b[38;5;241m/\u001b[39m ACK_RATIO) \u001b[38;5;241m*\u001b[39m (IP_HEADER_SIZE \u001b[38;5;241m+\u001b[39m TCP_HEADER_SIZE)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bitcoin_message_size \u001b[38;5;241m+\u001b[39m tcpip_overhead \u001b[38;5;241m+\u001b[39m ack_overhead\n\u001b[0;32m---> 21\u001b[0m df_tp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnet_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_tp\u001b[49m\u001b[38;5;241m.\u001b[39mparallel_apply(estimate_network_traffic, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df_tp' is not defined"
                    ]
                }
            ],
            "source": [
                "import math\n",
                "from pandarallel import pandarallel\n",
                "\n",
                "pandarallel.initialize(progress_bar=True)\n",
                "\n",
                "\n",
                "def estimate_network_traffic(row):\n",
                "    MAX_MTU_SIZE = 1500\n",
                "    BITCOIN_PROTOCOL_OVERHEAD = 24\n",
                "    TCP_HEADER_SIZE = 32\n",
                "    IP_HEADER_SIZE = 40 if row[\"ipv6\"] else 20\n",
                "    ACK_RATIO = 2\n",
                "    MSS = MAX_MTU_SIZE - IP_HEADER_SIZE - TCP_HEADER_SIZE\n",
                "    bitcoin_message_size = row[\"size\"] + BITCOIN_PROTOCOL_OVERHEAD\n",
                "    num_segments = math.ceil(bitcoin_message_size / MSS)\n",
                "    tcpip_overhead = num_segments * (IP_HEADER_SIZE + TCP_HEADER_SIZE)\n",
                "    ack_overhead = (num_segments / ACK_RATIO) * (IP_HEADER_SIZE + TCP_HEADER_SIZE)\n",
                "    return bitcoin_message_size + tcpip_overhead + ack_overhead\n",
                "\n",
                "\n",
                "df_tp[\"net_size\"] = df_tp.parallel_apply(estimate_network_traffic, axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Combine and aggregate data\n",
                "\n",
                "First, the dataframe contaiing empirical data from systemd's IP accounting is\n",
                "pivoted so it can be aggregated.\n",
                "\n",
                "Next, the pivoted df and the tracepoint df are aggregated to produce hourly and\n",
                "daily data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sys_t = (\n",
                "    df_sys.rename(columns={\"IPIngressBytes\": \"in\", \"IPEgressBytes\": \"out\"})[\n",
                "        [\"in\", \"out\"]\n",
                "    ]\n",
                "    .stack()\n",
                "    .rename(\"net_size\")\n",
                "    .reset_index()\n",
                "    .rename(columns={\"level_1\": \"flow\"})\n",
                "    .set_index(\"timestamp\")\n",
                ")\n",
                "\n",
                "\n",
                "def agg_sum(df, cols, freq, data=\"net_size\"):\n",
                "    \"\"\"Aggregate 'data' col based on datetime index with frequency 'freq', using\n",
                "    summation using 'cols' as differentiator.\"\"\"\n",
                "    df_tmp = df.copy()\n",
                "    df_tmp.index = df_tmp.index.floor(freq)\n",
                "    df_result = (\n",
                "        df_tmp.groupby([\"timestamp\"] + cols)[data]\n",
                "        .sum()\n",
                "        .reset_index()\n",
                "        .set_index(\"timestamp\")\n",
                "    )\n",
                "    return df_result\n",
                "\n",
                "\n",
                "dfs = {\n",
                "    \"est_hourly\": agg_sum(df_tp, [\"flow\", \"msg_type\"], freq=\"1h\"),\n",
                "    \"est_daily\": agg_sum(df_tp, [\"flow\", \"msg_type\"], freq=\"1d\"),\n",
                "    \"emp_hourly\": agg_sum(df_sys_t, [\"flow\"], freq=\"1h\"),\n",
                "    \"emp_daily\": agg_sum(df_sys_t, [\"flow\"], freq=\"1d\"),\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Format data\n",
                "\n",
                "Pivot `flow` column of dataframes to get `in` and `out` columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def pivot(df, index, columns=\"flow\", values=\"net_size\"):\n",
                "    \"\"\"Pivot dataframe: keep 'index' as rows, 'columns' as columns and 'values'\n",
                "    as values.  Set 'timestamp' as new index, fill missing values with zero and\n",
                "    convert new cols to int.\"\"\"\n",
                "\n",
                "    return (\n",
                "        df.reset_index()\n",
                "        .pivot(\n",
                "            index=index,\n",
                "            columns=columns,\n",
                "            values=values,\n",
                "        )\n",
                "        .rename_axis(None, axis=1)\n",
                "        .reset_index()\n",
                "        .set_index(\"timestamp\")\n",
                "        .fillna(0)\n",
                "        .astype({\"in\": \"int\", \"out\": \"int\"})\n",
                "    )\n",
                "\n",
                "\n",
                "dfs = {\n",
                "    \"est_hourly\": pivot(dfs[\"est_hourly\"], [\"timestamp\", \"msg_type\"]),\n",
                "    \"est_daily\": pivot(dfs[\"est_daily\"], [\"timestamp\", \"msg_type\"]),\n",
                "    \"emp_hourly\": pivot(dfs[\"emp_hourly\"], [\"timestamp\"]),\n",
                "    \"emp_daily\": pivot(dfs[\"emp_daily\"], [\"timestamp\"]),\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Handle restarts\n",
                "\n",
                "Whenever the `nix-bitcoin-monitor` systemd service (which performs the data\n",
                "collection) is restarted, the IP accounting counters are reset to zero. As a\n",
                "result, `diff()`ing consecutive readings is going to break (think large valule\n",
                "in previous row followed by small value in next row, leading to negative\n",
                "values). This is addressed by setting values smaller than zero to zero."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "for name, df in dfs.items():\n",
                "    if not name.startswith(\"emp_\"):\n",
                "        continue\n",
                "    for row in [\"in\", \"out\"]:\n",
                "        df.loc[df[row] < 0, row] = 0\n",
                "    dfs[name] = df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "for name, df in dfs.items():\n",
                "    df.to_csv(f\"data_{name}.csv.bz2\", compression=\"bz2\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.7 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
